# -*- coding: utf-8 -*-
"""Project 3.1_Sau.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u5WF7uTnGhGYRLQoFvnq1MyGsLu07E8N

#**1. Th∆∞ vi·ªán**
"""

import os, re, json, math, random, unicodedata, warnings
from collections import Counter, defaultdict
from typing import List, Tuple, Optional, Dict, Literal

#Khoa h·ªçc d·ªØ li·ªáu + v·∫Ω
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#D·ªØ li·ªáu & m√¥ h√¨nh ng√¥n ng·ªØ
from datasets import load_dataset                 # Hugging Face Datasets
from sentence_transformers import SentenceTransformer  # Embeddings (E5, SBERT, ‚Ä¶)

#Transformers baseline
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline

#Ti·ªÅn x·ª≠ l√Ω ti·∫øng Anh (stopwords/synonyms)
import nltk
from nltk.corpus import stopwords, wordnet as wn

#scikit-learn (train/test, vector ho√°, model, ƒë√°nh gi√°)
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier
from sklearn.svm import LinearSVC
from sklearn.naive_bayes import MultinomialNB, GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.cluster import KMeans
from sklearn.utils.class_weight import compute_class_weight

#C√¢n b·∫±ng d·ªØ li·ªáu (imbalanced-learn)
try:
    from imblearn.over_sampling import SMOTE, RandomOverSampler
    from imblearn.under_sampling import RandomUnderSampler
    from imblearn.pipeline import Pipeline as ImbPipeline
    _IMB_OK = True
except Exception:
    _IMB_OK = False
    warnings.warn("imbalanced-learn ch∆∞a c√†i; SMOTE/ROS/RUS s·∫Ω b·ªã t·∫Øt. C√†i: pip install imbalanced-learn")


# import warnings
warnings.filterwarnings("ignore")

CACHE_DIR = "./cache"

# T·∫°o block c·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n/ Figure/Report paths
from types import SimpleNamespace

FIG_ROOT = os.path.join("pdf", "Figures")
PATHS = SimpleNamespace(
    root=FIG_ROOT,
    balanced=os.path.join(FIG_ROOT, "balanced"),
    all_models=os.path.join(FIG_ROOT, "all_models"),
)

# T·∫°o th∆∞ m·ª•c
for d in (PATHS.root, PATHS.balanced, PATHS.all_models):
    os.makedirs(d, exist_ok=True)

"""#**2. X·ª≠ l√Ω d·ªØ li·ªáu**"""

# Load the dataset from the specified cache directory
ds = load_dataset("UniverseTBD/arxiv-abstracts-large", cache_dir=CACHE_DIR)
ds

all_categories = ds['train']['categories'][:1000]
print(set(all_categories))

all_categories = ds['train']['categories']
category_set = set()

# Collect unique labels
for category in all_categories:
    parts = category.split(' ')
    for part in parts:
        topic = part.split('.')[0]
        category_set.add(topic)

# Sort the labels and print them
sorted_categories= sorted(list(category_set), key=lambda x: x.lower())
print(f'There are {len(sorted_categories)} unique primary categories in the dataset:')
for category in sorted_categories:
    print(category)

# load 1000 samples with single label belonging to specific categories
samples = []
CATEGORIES_TO_SELECT = ['astro-ph', 'cond-mat', 'cs', 'math', 'physics']
for s in ds['train']:
    if len(s['categories'].split(' ')) != 1:
        continue

    cur_category = s['categories'].strip().split('.')[0]
    if cur_category not in CATEGORIES_TO_SELECT:
        continue

    samples.append(s)

    if len(samples) >= 1000:
        break
print(f"Number of samples: {len(samples)}")

for sample in samples[:3]:
    print(f"Category: {sample['categories']}")
    print("Abstract:", sample['abstract'])
    print("#" * 20 + "\n")

preprocessed_samples = []
for s in samples:
    abstract = s['abstract']

    # Remove \n characters in the middle and leading/trailing spaces
    abstract = abstract.strip().replace("\n", " ")

    # Remove special characters
    abstract = re.sub(r'[^\w\s]', '', abstract)

    # Remove digits
    abstract = re.sub(r'\d+', '', abstract)

    # Remove extra spaces
    abstract = re.sub(r'\s+', ' ', abstract).strip()

    # Convert to lower case
    abstract = abstract.lower()

    # for the label, we only keep the first part
    parts = s['categories'].split(' ')
    category = parts[0].split('.')[0]

    preprocessed_samples.append({
        "text": abstract,
        "label": category
    })

# print first 3 preprocessed samples
for sample in preprocessed_samples[:3]:
    print(f"Label: {sample['label']}")
    print("Text:", sample['text'])
    print("#" * 20 + "\n")

labels = set([s['label'] for s in preprocessed_samples])
# Sort and print unique labels
sorted_labels = sorted(labels)
for label in sorted_labels:
    print(label)

label_to_id = {label: i for i, label in enumerate(sorted_labels)}
id_to_label = {i: label for i, label in enumerate(sorted_labels)}

# Print label to ID mapping
print("Label to ID mapping:")
for label, id_ in label_to_id.items():
    print(f"{label} --> {id_}")

X_full = [sample['text'] for sample in preprocessed_samples]
y_full = [label_to_id[sample['label']] for sample in preprocessed_samples]

X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.2, random_state=42, stratify=y_full)

print(f"Training samples: {len(X_train)}")
print(f"Test samples: {len(X_test)}")

"""# **3. TƒÉng c∆∞·ªùng d·ªØ li·ªáu**"""

# üîÅ Data Augmentation + Class-Balanced Upsampling (put this right after train_test_split)

# ‚öôÔ∏è Config
AUGMENT_ENABLED      = True      # t·∫Øt/m·ªü augmentation
TARGET_PER_CLASS     = 300       # m·ªói l·ªõp s·∫Ω ƒë∆∞·ª£c tƒÉng l√™n t·ªëi ƒëa m·ª©c n√†y (ho·∫∑c max hi·ªán c√≥, tu·ª≥ l·ªõp)
ALPHA_DELETE         = 0.10      # x√°c su·∫•t xo√° t·ª´
ALPHA_SWAP           = 0.10      # t·ª∑ l·ªá ho√°n v·ªã ~ (ALPHA_SWAP * s·ªë t·ª´)
ALPHA_SYNONYM_RATIO  = 0.10      # t·ª∑ l·ªá t·ª´ s·∫Ω ƒë∆∞·ª£c thay b·∫±ng ƒë·ªìng nghƒ©a (n·∫øu c√≥ wordnet)
NUM_AUG_PER_SAMPLE   = 1         # m·ªói vƒÉn b·∫£n g·ªëc sinh ra bao nhi√™u bi·∫øn th·ªÉ
RANDOM_SEED          = 42

random.seed(RANDOM_SEED)

#WordNet synonyms
try:
    import nltk
    nltk.data.find('corpora/wordnet')
except Exception:
    try:
        import nltk
        nltk.download('wordnet', quiet=True)
        nltk.download('omw-1.4', quiet=True)
    except Exception:
        pass

try:
    from nltk.corpus import wordnet as wn
    _WORDNET_OK = True
except Exception:
    _WORDNET_OK = False

def _tokenize_simple(s: str) -> List[str]:
    return s.split()

def _random_deletion(tokens: List[str], p: float) -> List[str]:
    if not tokens:
        return tokens
    out = [t for t in tokens if random.random() > p]
    return out if out else tokens  # kh√¥ng ƒë·ªÉ r·ªóng

def _random_swap(tokens: List[str], n_swaps: int) -> List[str]:
    if len(tokens) < 2 or n_swaps <= 0:
        return tokens
    tokens = tokens.copy()
    for _ in range(n_swaps):
        i, j = random.sample(range(len(tokens)), 2)
        tokens[i], tokens[j] = tokens[j], tokens[i]
    return tokens

def _get_synonyms(word: str) -> List[str]:
    if not _WORDNET_OK or not word.isalpha():
        return []
    syns = set()
    for syn in wn.synsets(word):
        for lem in syn.lemmas():
            w = lem.name().replace('_', ' ').lower()
            if w != word:
                syns.add(w)
    return list(syns)

def _random_synonym_replace(tokens: List[str], ratio: float) -> List[str]:
    if not _WORDNET_OK or ratio <= 0 or not tokens:
        return tokens
    tokens = tokens.copy()
    n_changes = max(1, int(len(tokens) * ratio))
    idxs = list(range(len(tokens)))
    random.shuffle(idxs)
    changed = 0
    for i in idxs:
        syns = _get_synonyms(tokens[i])
        if syns:
            tokens[i] = random.choice(syns)
            changed += 1
        if changed >= n_changes:
            break
    return tokens

def eda_augment(text: str,
                alpha_del=ALPHA_DELETE,
                alpha_swap=ALPHA_SWAP,
                alpha_syn=ALPHA_SYNONYM_RATIO,
                num_aug=NUM_AUG_PER_SAMPLE) -> List[str]:
    """
    EDA c∆° b·∫£n: xo√°, ho√°n v·ªã, thay t·ª´ ƒë·ªìng nghƒ©a (n·∫øu c√≥).
    """
    out = []
    base_tokens = _tokenize_simple(text)
    for _ in range(num_aug):
        tokens = base_tokens
        # xo√° ng·∫´u nhi√™n
        tokens = _random_deletion(tokens, alpha_del)
        # ho√°n v·ªã ng·∫´u nhi√™n
        n_swaps = max(1, int(len(tokens) * alpha_swap)) if len(tokens) > 1 else 0
        tokens = _random_swap(tokens, n_swaps)
        # thay t·ª´ ƒë·ªìng nghƒ©a
        tokens = _random_synonym_replace(tokens, alpha_syn)
        out.append(' '.join(tokens))
    return out

def augment_and_balance(X_train: List[str],
                        y_train: List[int],
                        target_per_class: int = TARGET_PER_CLASS,
                        seed: int = RANDOM_SEED):
    """
    TƒÉng c∆∞·ªùng + c√¢n b·∫±ng theo l·ªõp cho t·ªõi khi m·ªói l·ªõp ƒë·∫°t √≠t nh·∫•t target_per_class
    (ho·∫∑c t·ªõi m·ª©c g·∫ßn nh·∫•t c√≥ th·ªÉ).
    """
    random.seed(seed)
    X_train = list(X_train)
    y_train = list(y_train)

    counts = Counter(y_train)
    classes = sorted(counts.keys())
    cur_max = max(counts.values()) if counts else 0
    target = max(min(target_per_class, max(cur_max, 1)), 1)

    # Gom vƒÉn b·∫£n theo l·ªõp
    by_class = {c: [x for x, y in zip(X_train, y_train) if y == c] for c in classes}

    X_aug, y_aug = [], []
    for c in classes:
        texts = by_class[c]
        need = max(0, target - len(texts))
        if need == 0 or not texts:
            continue

        # L·∫∑p qua vƒÉn b·∫£n g·ªëc, sinh bi·∫øn th·ªÉ cho t·ªõi khi ƒë·ªß
        i = 0
        while need > 0:
            t = texts[i % len(texts)]
            for aug in eda_augment(t):
                X_aug.append(aug)
                y_aug.append(c)
                need -= 1
                if need <= 0:
                    break
            i += 1

    # Gh√©p v√†o train
    X_new = X_train + X_aug
    y_new = y_train + y_aug

    after = Counter(y_new)
    print("üîß Augmented per-class counts:", dict(after))
    print(f"üîº Train size: {len(X_train)} ‚Üí {len(X_new)} (added {len(X_aug)})")
    return X_new, y_new

# Th·ª±c thi augmentation (n·∫øu b·∫≠t)
if AUGMENT_ENABLED:
    X_train, y_train = augment_and_balance(
        X_train, y_train, target_per_class=TARGET_PER_CLASS, seed=RANDOM_SEED
    )
else:
    print("Augmentation disabled ‚Äî skipping.")

bow_vectorizer = CountVectorizer()
X_train_bow = bow_vectorizer.fit_transform(X_train)
X_test_bow  = bow_vectorizer.transform(X_test)

tfidf_vectorizer = TfidfVectorizer()
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf  = tfidf_vectorizer.transform(X_test)

#EmbeddingVectorizer
class EmbeddingVectorizer:
    def __init__(self, model_name: str = "intfloat/multilingual-e5-base",
                 normalize: bool = True, device: Optional[str] = None):
        self.model = SentenceTransformer(model_name, device=device)
        self.normalize = normalize

    def _format_inputs(self, texts: List[str], mode: str = "query") -> List[str]:
        if mode == "raw":
            return texts
        if mode not in {"query", "passage"}:
            raise ValueError("mode ph·∫£i l√† 'query', 'passage' ho·∫∑c 'raw'")
        return [f"{mode}: {t.strip()}" for t in texts]

    def transform_numpy(self, texts: List[str], mode: str = "query") -> np.ndarray:
        inputs = self._format_inputs(texts, mode)
        embs = self.model.encode(inputs, normalize_embeddings=self.normalize)
        return np.array(embs)

#T·∫°o embedding
embedding_vectorizer = EmbeddingVectorizer()  # m·∫∑c ƒë·ªãnh 'intfloat/multilingual-e5-base'
X_train_embeddings = embedding_vectorizer.transform_numpy(X_train)  # shape (N, 768)
X_test_embeddings  = embedding_vectorizer.transform_numpy(X_test)

"""# **4. C√¢n b·∫±ng d·ªØ li·ªáu train**"""

BALANCE_BOW      = "over"   # 'none' | 'over' | 'under'  (kh√¥ng khuy·∫øn ngh·ªã 'smote' cho sparse)
BALANCE_TFIDF    = "over"   # 'none' | 'over' | 'under'
BALANCE_EMB      = "smote"  # 'none' | 'over' | 'under' | 'smote' (SMOTE t·ªët cho embeddings)

RANDOM_STATE     = 42

def _print_counts(y, note):
    cnt = Counter(y)
    print(f"{note} ‚Äî s·ªë m·∫´u theo l·ªõp:", dict(sorted(cnt.items())))

# Th·ª≠ d√πng imblearn; n·∫øu thi·∫øu th√¨ fallback th·ªß c√¥ng cho 'over'/'under'
try:
    from imblearn.over_sampling import RandomOverSampler
    from imblearn.under_sampling import RandomUnderSampler
    from imblearn.over_sampling import SMOTE
    _IMB_OK = True
except Exception:
    _IMB_OK = False
    print("‚ö†Ô∏è Thi·∫øu imblearn ‚Äî s·∫Ω d√πng fallback ƒë∆°n gi·∫£n cho over/under. C√†i b·∫±ng: pip install imbalanced-learn")

def _fallback_resample_over(X, y):
    """Oversample th·ªß c√¥ng ƒë·∫øn max_count."""
    y = np.asarray(y)
    classes, counts = np.unique(y, return_counts=True)
    max_count = counts.max()
    idx_all = np.arange(len(y))
    new_idx = []
    for c in classes:
        idx_c = idx_all[y == c]
        if len(idx_c) == 0:
            continue
        reps = int(np.ceil(max_count / len(idx_c)))
        tiled = np.tile(idx_c, reps)[:max_count]
        new_idx.append(tiled)
    new_idx = np.concatenate(new_idx)
    if hasattr(X, "toarray"):  # sparse
        X_new = X[new_idx]
    else:
        X_new = X[new_idx] if isinstance(X, np.ndarray) else [X[i] for i in new_idx]
    y_new = y[new_idx]
    return X_new, y_new

def _fallback_resample_under(X, y):
    """Undersample th·ªß c√¥ng xu·ªëng min_count."""
    y = np.asarray(y)
    classes, counts = np.unique(y, return_counts=True)
    min_count = counts.min()
    rng = np.random.default_rng(RANDOM_STATE)
    idx_all = np.arange(len(y))
    new_idx = []
    for c in classes:
        idx_c = idx_all[y == c]
        take = rng.choice(idx_c, size=min_count, replace=False)
        new_idx.append(take)
    new_idx = np.concatenate(new_idx)
    rng.shuffle(new_idx)
    if hasattr(X, "toarray"):  # sparse
        X_new = X[new_idx]
    else:
        X_new = X[new_idx] if isinstance(X, np.ndarray) else [X[i] for i in new_idx]
    y_new = y[new_idx]
    return X_new, y_new

def make_balanced(X, y, strategy: str, is_sparse: bool, for_embeddings: bool = False):
    """
    strategy: 'none' | 'over' | 'under' | 'smote'
    is_sparse: True cho BoW/TF-IDF; False cho embeddings
    for_embeddings: True n·∫øu l√† embeddings (dense) => cho ph√©p SMOTE
    """
    if strategy == "none":
        return X, y

    if strategy == "smote":
        if not for_embeddings or is_sparse:
            print("‚ö†Ô∏è B·ªè qua SMOTE cho d·ªØ li·ªáu sparse (BoW/TF-IDF). D√πng 'over' thay th·∫ø.")
            strategy = "over"
        elif not _IMB_OK:
            print("‚ö†Ô∏è Thi·∫øu imblearn ‚Äî kh√¥ng d√πng ƒë∆∞·ª£c SMOTE. D√πng 'over' thay th·∫ø.")
            strategy = "over"

    if not _IMB_OK and strategy in {"over", "under"}:
        # Fallback th·ªß c√¥ng
        return (_fallback_resample_over(X, y) if strategy == "over"
                else _fallback_resample_under(X, y))

    # D√πng imblearn
    if strategy == "over":
        sampler = RandomOverSampler(random_state=RANDOM_STATE)
    elif strategy == "under":
        sampler = RandomUnderSampler(random_state=RANDOM_STATE)
    elif strategy == "smote":
        # SMOTE cho embeddings (dense)
        sampler = SMOTE(random_state=RANDOM_STATE, k_neighbors=5)
    else:
        return X, y

    # imblearn h·ªó tr·ª£ y nh∆∞ m·∫£ng 1D
    y_arr = np.asarray(y)
    X_bal, y_bal = sampler.fit_resample(X, y_arr)
    return X_bal, y_bal

# ===== Th·ª±c thi c√¢n b·∫±ng =====
_print_counts(y_train, "Tr∆∞·ªõc c√¢n b·∫±ng")

# BoW (sparse)
is_sparse_bow = hasattr(X_train_bow, "toarray")
X_train_bow_bal, y_train_bow_bal = make_balanced(
    X_train_bow, y_train, strategy=BALANCE_BOW, is_sparse=is_sparse_bow, for_embeddings=False
)
_print_counts(y_train_bow_bal, f"BoW sau c√¢n b·∫±ng ({BALANCE_BOW})")

# TF-IDF (sparse)
is_sparse_tfidf = hasattr(X_train_tfidf, "toarray")
X_train_tfidf_bal, y_train_tfidf_bal = make_balanced(
    X_train_tfidf, y_train, strategy=BALANCE_TFIDF, is_sparse=is_sparse_tfidf, for_embeddings=False
)
_print_counts(y_train_tfidf_bal, f"TF-IDF sau c√¢n b·∫±ng ({BALANCE_TFIDF})")

# Embeddings (dense) ‚Äî ∆∞u ti√™n SMOTE
is_sparse_emb = False
X_train_emb_bal, y_train_emb_bal = make_balanced(
    X_train_embeddings, y_train, strategy=BALANCE_EMB, is_sparse=is_sparse_emb, for_embeddings=True
)
_print_counts(y_train_emb_bal, f"Embeddings sau c√¢n b·∫±ng ({BALANCE_EMB})")

"""# **5. Hu·∫•n luy·ªán l·∫°i tr√™n t·∫≠p ƒë√£ c√¢n b·∫±ng**

"""

# üéØ Confusion matrices ‚Äî Sau c√¢n b·∫±ng (v√† so s√°nh n·∫øu c√≥ b·∫£n "pre")
# B·∫£o ƒë·∫£m danh s√°ch nh√£n hi·ªÉn th·ªã ƒë√∫ng th·ª© t·ª± id
if 'sorted_labels' not in globals():
    # fallback theo id xu·∫•t hi·ªán trong y_test
    uniq = sorted(set(y_test))
    sorted_labels = [str(i) for i in uniq]
labels_idx = list(range(len(sorted_labels)))

# ===== Ki·ªÉm tra bi·∫øn c·∫ßn thi·∫øt =====
_required = [
    'X_train_bow_bal','y_train_bow_bal','X_test_bow',
    'X_train_tfidf_bal','y_train_tfidf_bal','X_test_tfidf',
    'X_train_emb_bal','y_train_emb_bal','X_test_embeddings',
    'y_test'
]
_missing = [v for v in _required if v not in globals()]
assert not _missing, f"Thi·∫øu bi·∫øn: {_missing}. H√£y ch·∫°y cell ti·ªÅn x·ª≠ l√Ω / vector h√≥a tr∆∞·ªõc."

# ===== Labels hi·ªÉn th·ªã =====
if 'sorted_labels' not in globals():
    if 'id_to_label' in globals() and isinstance(id_to_label, dict):
        sorted_labels = [id_to_label[i] for i in range(len(id_to_label))]
    else:
        uniq = sorted(set(list(y_train_bow_bal) + list(y_test)))
        sorted_labels = [str(i) for i in uniq]

# ===== Helpers chung =====
def _to_dense(X): # cho GaussianNB
    return X.toarray() if hasattr(X, "toarray") else X

def _safe_report(y_true, y_pred):
    return classification_report(y_true, y_pred, target_names=sorted_labels, output_dict=True)

def _summarize(name, y_true, y_pred):
    return dict(
        model_feature=name,
        accuracy=accuracy_score(y_true, y_pred),
        f1_macro=f1_score(y_true, y_pred, average="macro"),
        f1_weighted=f1_score(y_true, y_pred, average="weighted"),
    )

# KNN
def train_and_test_knn(X_tr, y_tr, X_te, y_te, n_neighbors: int = 5):
    clf = KNeighborsClassifier(n_neighbors=n_neighbors)
    clf.fit(X_tr, y_tr)
    return clf.predict(X_te)

knn_bow_labels   = train_and_test_knn(X_train_bow_bal,   y_train_bow_bal,   X_test_bow,        y_test)
knn_tfidf_labels = train_and_test_knn(X_train_tfidf_bal, y_train_tfidf_bal, X_test_tfidf,      y_test)
knn_emb_labels   = train_and_test_knn(X_train_emb_bal,   y_train_emb_bal,   X_test_embeddings, y_test)

# Decision Tree
def train_and_test_decision_tree_bal(X_tr, y_tr, X_te, y_te, use_class_weight=True, random_state: int = 42):
    cw = "balanced" if use_class_weight else None
    clf = DecisionTreeClassifier(random_state=random_state, class_weight=cw)
    clf.fit(X_tr, y_tr)
    return clf.predict(X_te)

dt_bow_labels   = train_and_test_decision_tree_bal(X_train_bow_bal,   y_train_bow_bal,   X_test_bow,        y_test, use_class_weight=True)
dt_tfidf_labels = train_and_test_decision_tree_bal(X_train_tfidf_bal, y_train_tfidf_bal, X_test_tfidf,      y_test, use_class_weight=True)
dt_emb_labels   = train_and_test_decision_tree_bal(X_train_emb_bal,   y_train_emb_bal,   X_test_embeddings, y_test, use_class_weight=True)

# Naive Bayes
def train_and_test_naive_bayes(X_tr, y_tr, X_te, y_te):
    clf = GaussianNB()
    clf.fit(_to_dense(X_tr), y_tr)
    return clf.predict(_to_dense(X_te))

nb_bow_labels   = train_and_test_naive_bayes(X_train_bow_bal,   y_train_bow_bal,   X_test_bow,        y_test)
nb_tfidf_labels = train_and_test_naive_bayes(X_train_tfidf_bal, y_train_tfidf_bal, X_test_tfidf,      y_test)
nb_emb_labels   = train_and_test_naive_bayes(X_train_emb_bal,   y_train_emb_bal,   X_test_embeddings, y_test)

# ===== 2) LinearSVC / Logistic Regression / Ridge =====
def _fit_eval(model, X_tr, y_tr, X_te, y_te, name: str, to_dense: bool = False):
    if to_dense:
        X_tr = _to_dense(X_tr); X_te = _to_dense(X_te)
    model.fit(X_tr, y_tr)
    return model.predict(X_te)

svc_bow_labels   = _fit_eval(LinearSVC(C=1.0, class_weight='balanced', random_state=42),
                             X_train_bow_bal, y_train_bow_bal, X_test_bow, y_test, "LinearSVC ‚Äî BoW")
svc_tfidf_labels = _fit_eval(LinearSVC(C=1.0, class_weight='balanced', random_state=42),
                             X_train_tfidf_bal, y_train_tfidf_bal, X_test_tfidf, y_test, "LinearSVC ‚Äî TF-IDF")
svc_emb_labels   = _fit_eval(LinearSVC(C=1.0, class_weight='balanced', random_state=42),
                             X_train_emb_bal, y_train_emb_bal, X_test_embeddings, y_test, "LinearSVC ‚Äî Embeddings")

log_bow_labels   = _fit_eval(LogisticRegression(C=1.0, penalty='l2', solver='lbfgs', max_iter=2000,
                                                class_weight='balanced', random_state=42),
                             X_train_bow_bal, y_train_bow_bal, X_test_bow, y_test, "LogReg ‚Äî BoW")
log_tfidf_labels = _fit_eval(LogisticRegression(C=1.0, penalty='l2', solver='lbfgs', max_iter=2000,
                                                class_weight='balanced', random_state=42),
                             X_train_tfidf_bal, y_train_tfidf_bal, X_test_tfidf, y_test, "LogReg ‚Äî TF-IDF")
log_emb_labels   = _fit_eval(LogisticRegression(C=1.0, penalty='l2', solver='lbfgs', max_iter=2000,
                                                class_weight='balanced', random_state=42),
                             X_train_emb_bal, y_train_emb_bal, X_test_embeddings, y_test, "LogReg ‚Äî Embeddings")

ridge_bow_labels   = _fit_eval(RidgeClassifier(alpha=1.0, class_weight='balanced', random_state=42),
                               X_train_bow_bal, y_train_bow_bal, X_test_bow, y_test, "Ridge ‚Äî BoW")
ridge_tfidf_labels = _fit_eval(RidgeClassifier(alpha=1.0, class_weight='balanced', random_state=42),
                               X_train_tfidf_bal, y_train_tfidf_bal, X_test_tfidf, y_test, "Ridge ‚Äî TF-IDF")
ridge_emb_labels   = _fit_eval(RidgeClassifier(alpha=1.0, class_weight='balanced', random_state=42),
                               X_train_emb_bal, y_train_emb_bal, X_test_embeddings, y_test, "Ridge ‚Äî Embeddings")

# ===== 3) B·∫£ng t√≥m t·∫Øt nhanh =====
rows = []
rows += [_summarize("KNN ‚Äî BoW",         y_test, knn_bow_labels)]
rows += [_summarize("KNN ‚Äî TF-IDF",      y_test, knn_tfidf_labels)]
rows += [_summarize("KNN ‚Äî Embeddings",  y_test, knn_emb_labels)]

rows += [_summarize("Decision Tree ‚Äî BoW",        y_test, dt_bow_labels)]
rows += [_summarize("Decision Tree ‚Äî TF-IDF",     y_test, dt_tfidf_labels)]
rows += [_summarize("Decision Tree ‚Äî Embeddings", y_test, dt_emb_labels)]

rows += [_summarize("Naive Bayes ‚Äî BoW",         y_test, nb_bow_labels)]
rows += [_summarize("Naive Bayes ‚Äî TF-IDF",      y_test, nb_tfidf_labels)]
rows += [_summarize("Naive Bayes ‚Äî Embeddings",  y_test, nb_emb_labels)]

rows += [_summarize("LinearSVC ‚Äî BoW",        y_test, svc_bow_labels)]
rows += [_summarize("LinearSVC ‚Äî TF-IDF",     y_test, svc_tfidf_labels)]
rows += [_summarize("LinearSVC ‚Äî Embeddings", y_test, svc_emb_labels)]

rows += [_summarize("LogReg ‚Äî BoW",        y_test, log_bow_labels)]
rows += [_summarize("LogReg ‚Äî TF-IDF",     y_test, log_tfidf_labels)]
rows += [_summarize("LogReg ‚Äî Embeddings", y_test, log_emb_labels)]

rows += [_summarize("Ridge ‚Äî BoW",        y_test, ridge_bow_labels)]
rows += [_summarize("Ridge ‚Äî TF-IDF",     y_test, ridge_tfidf_labels)]
rows += [_summarize("Ridge ‚Äî Embeddings", y_test, ridge_emb_labels)]

results_df_all = (pd.DataFrame(rows)
                  .sort_values(["f1_macro","accuracy"], ascending=False)
                  .reset_index(drop=True))

print("\nüèÅ T·ªïng h·ª£p (top 10 theo F1-macro):")
try:
    from IPython.display import display
    display(results_df_all.head(10))
except Exception:
    print(results_df_all.head(10))

best = results_df_all.iloc[0]
print(f"üèÜ Best: {best['model_feature']} | Acc={best['accuracy']:.4f} | F1-macro={best['f1_macro']:.4f}")

"""# **6. T·ªïng h·ª£p k·∫øt qu·∫£ + V·∫Ω t·∫•t c·∫£ m√¥ h√¨nh**"""

# ---- Chu·∫©n b·ªã nh√£n hi·ªÉn th·ªã ----
assert 'y_test' in globals(), "C·∫ßn c√≥ y_test t·ª´ b∆∞·ªõc split d·ªØ li·ªáu."
if 'sorted_labels' not in globals():
    uniq = sorted(set(y_test))
    sorted_labels = [str(i) for i in uniq]
labels_idx = list(range(len(sorted_labels)))

# ---- Helper v·∫Ω Confusion (t·∫°o n·∫øu ch∆∞a c√≥) ----
def _cm_annot(cm: np.ndarray) -> np.ndarray:
    cmn = cm.astype(float) / np.clip(cm.sum(axis=1, keepdims=True), 1, None)
    ann = np.empty_like(cm).astype(str)
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ann[i, j] = f"{cm[i, j]}\n({cmn[i, j]:.2%})"
    return ann


# 1) Thu th·∫≠p d·ª± ƒëo√°n m·ªçi m√¥ h√¨nh
ALL_CANDIDATES = [
    # KNN
    ("KNN ‚Äî BoW", "knn_bow_labels"),
    ("KNN ‚Äî TF-IDF", "knn_tfidf_labels"),
    ("KNN ‚Äî Embeddings", "knn_emb_labels"),
    # Decision Tree
    ("Decision Tree ‚Äî BoW", "dt_bow_labels"),
    ("Decision Tree ‚Äî TF-IDF", "dt_tfidf_labels"),
    ("Decision Tree ‚Äî Embeddings", "dt_emb_labels"),
    # Naive Bayes
    ("Naive Bayes ‚Äî BoW", "nb_bow_labels"),
    ("Naive Bayes ‚Äî TF-IDF", "nb_tfidf_labels"),
    ("Naive Bayes ‚Äî Embeddings", "nb_emb_labels"),
    # LinearSVC
    ("LinearSVC ‚Äî BoW", "svc_bow_labels"),
    ("LinearSVC ‚Äî TF-IDF", "svc_tfidf_labels"),
    ("LinearSVC ‚Äî Embeddings", "svc_emb_labels"),
    # Logistic Regression
    ("LogReg ‚Äî BoW", "log_bow_labels"),
    ("LogReg ‚Äî TF-IDF", "log_tfidf_labels"),
    ("LogReg ‚Äî Embeddings", "log_emb_labels"),
    # Ridge
    ("Ridge ‚Äî BoW", "ridge_bow_labels"),
    ("Ridge ‚Äî TF-IDF", "ridge_tfidf_labels"),
    ("Ridge ‚Äî Embeddings", "ridge_emb_labels"),
]

pred_map = {}
missing = []
for disp, var in ALL_CANDIDATES:
    if var in globals():
        pred_map[disp] = globals()[var]
    else:
        missing.append(disp)

if not pred_map:
    raise RuntimeError("Kh√¥ng t√¨m th·∫•y bi·∫øn d·ª± ƒëo√°n n√†o. H√£y ch·∫°y cell hu·∫•n luy·ªán ƒë·ªÉ t·∫°o c√°c *_labels tr∆∞·ªõc.")

if missing:
    print("‚ÑπÔ∏è Ch∆∞a c√≥ d·ª± ƒëo√°n cho:", ", ".join(missing))

# 2) B·∫£ng t·ªïng h·ª£p metrics
rows = []
for name, y_pred in pred_map.items():
    acc = accuracy_score(y_test, y_pred)
    f1m = f1_score(y_test, y_pred, average="macro")
    f1w = f1_score(y_test, y_pred, average="weighted")
    algo, repr_ = name.split(" ‚Äî ")
    rows.append({
        "model_feature": name,
        "algo": algo,
        "repr": repr_,
        "accuracy": acc,
        "f1_macro": f1m,
        "f1_weighted": f1w
    })

results_df_all = (pd.DataFrame(rows)
                  .sort_values(["f1_macro","accuracy"], ascending=False)
                  .reset_index(drop=True))

print("üèÅ B·∫£ng t·ªïng h·ª£p (top 12 theo F1-macro):")
try:
    from IPython.display import display
    display(results_df_all.head(12))
except Exception:
    print(results_df_all.head(12))

# 3) Bi·ªÉu ƒë·ªì t·ªïng h·ª£p
plt.figure(figsize=(10, 5))
sns.barplot(data=results_df_all, x="model_feature", y="f1_macro",
            order=results_df_all["model_feature"])
plt.xticks(rotation=30, ha="right")
plt.ylabel("F1-macro"); plt.title("F1-macro theo m√¥ h√¨nh‚Äìbi·ªÉu di·ªÖn")
plt.tight_layout(); plt.show()

plt.figure(figsize=(10, 5))
sns.barplot(data=results_df_all, x="model_feature", y="accuracy",
            order=results_df_all["model_feature"])
plt.xticks(rotation=30, ha="right")
plt.ylabel("Accuracy"); plt.title("Accuracy theo m√¥ h√¨nh‚Äìbi·ªÉu di·ªÖn")
plt.tight_layout(); plt.show()

# Bi·ªÉu ƒë·ªì theo t·ª´ng bi·ªÉu di·ªÖn
for repr_name in ["BoW", "TF-IDF", "Embeddings"]:
    sub = results_df_all[results_df_all["repr"] == repr_name].copy()
    if sub.empty:
        continue
    plt.figure(figsize=(7.5, 4))
    sns.barplot(data=sub, x="algo", y="f1_macro",
                order=sub.sort_values("f1_macro", ascending=False)["algo"])
    plt.title(f"F1-macro ‚Äî {repr_name}")
    plt.xlabel("M√¥ h√¨nh"); plt.ylabel("F1-macro")
    plt.tight_layout(); plt.show()

# 4) L∆∞u Confusion Matrix cho T·∫§T C·∫¢ m√¥ h√¨nh
def _save_cm(y_true, y_pred, title, save_dir, fname_stub, show=True):
    cm = confusion_matrix(y_true, y_pred, labels=labels_idx)
    ann = _cm_annot(cm)
    plt.figure(figsize=(6.5, 5))
    sns.heatmap(cm, annot=ann, fmt="", cmap="Blues",
                xticklabels=sorted_labels, yticklabels=sorted_labels,
                cbar=False, linewidths=1, linecolor='black')
    plt.xlabel("Predicted"); plt.ylabel("True"); plt.title(title)
    plt.tight_layout()
    fn = re.sub(r"[^a-zA-Z0-9\-_.]+", "_", fname_stub) + "_cm.pdf"
    path = os.path.join(save_dir, fn)   # <-- d√πng tham s·ªë save_dir
    plt.savefig(path, bbox_inches="tight")
    if show:
        plt.show()
    else:
        plt.close()

# Hi·ªÉn th·ªã t·ªëi ƒëa N h√¨nh t·ªët nh·∫•t; ph·∫ßn c√≤n l·∫°i ch·ªâ l∆∞u
SHOW_TOP_N = 9
order_names = results_df_all["model_feature"].tolist()
for i, name in enumerate(order_names):
    _save_cm(y_test, pred_map[name], title=f"{name} ‚Äî Confusion Matrix",
             save_dir=PATHS.all_models, fname_stub=name, show=(i < SHOW_TOP_N))

if 'sorted_labels' not in globals():
    assert 'y_test' in globals(), "C·∫ßn y_test ƒë·ªÉ suy ra nh√£n."
    uniq = sorted(set(y_test))
    sorted_labels = [str(i) for i in uniq]
labels_idx = list(range(len(sorted_labels)))

if '_cm_annot' not in globals():
    def _cm_annot(cm: np.ndarray) -> np.ndarray:
        cmn = cm.astype(float) / np.clip(cm.sum(axis=1, keepdims=True), 1, None)
        ann = np.empty_like(cm).astype(str)
        for i in range(cm.shape[0]):
            for j in range(cm.shape[1]):
                ann[i, j] = f"{cm[i, j]}\n({cmn[i, j]:.2%})"
        return ann

if 'plot_confusion_single' not in globals():
    def plot_confusion_single(y_true, y_pred, class_names=None, title="", save_path=None):
        if class_names is None:
            class_names = sorted_labels
        cm = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))
        ann = _cm_annot(cm)
        plt.figure(figsize=(6.5, 5))
        sns.heatmap(cm, annot=ann, fmt="", cmap="Blues",
                    xticklabels=class_names, yticklabels=class_names,
                    cbar=False, linewidths=1, linecolor='black')
        plt.xlabel("Predicted"); plt.ylabel("True"); plt.title(title)
        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, bbox_inches="tight")
        plt.show()

if 'compare_confusions' not in globals():
    def compare_confusions(y_true, y_pred_pre, y_pred_post, class_names=None,
                           title_pre="Tr∆∞·ªõc c√¢n b·∫±ng", title_post="Sau c√¢n b·∫±ng",
                           save_path=None):
        if class_names is None:
            class_names = sorted_labels
        labels = range(len(class_names))
        cm_pre  = confusion_matrix(y_true, y_pred_pre,  labels=labels)
        cm_post = confusion_matrix(y_true, y_pred_post, labels=labels)
        ann_pre, ann_post = _cm_annot(cm_pre), _cm_annot(cm_post)

        fig, axes = plt.subplots(1, 2, figsize=(13, 5), sharex=True, sharey=True)
        sns.heatmap(cm_pre,  annot=ann_pre,  fmt="", cmap="Blues",
                    xticklabels=class_names, yticklabels=class_names,
                    cbar=False, linewidths=1, linecolor='black', ax=axes[0])
        axes[0].set_title(title_pre); axes[0].set_xlabel("Predicted"); axes[0].set_ylabel("True")

        sns.heatmap(cm_post, annot=ann_post, fmt="", cmap="Blues",
                    xticklabels=class_names, yticklabels=class_names,
                    cbar=False, linewidths=1, linecolor='black', ax=axes[1])
        axes[1].set_title(title_post); axes[1].set_xlabel("Predicted"); axes[1].set_ylabel("")
        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, bbox_inches="tight")
        plt.show()


# 5) V·∫º CHARTS
# ====== V·∫º KNN ======
if 'knn_bow_labels_pre' in globals():
    compare_confusions(y_test, knn_bow_labels_pre, knn_bow_labels,
                       sorted_labels,
                       title_pre="KNN-BoW (tr∆∞·ªõc c√¢n b·∫±ng)", title_post="KNN-BoW (sau c√¢n b·∫±ng)",
                       save_path=os.path.join(PATHS.balanced, "knn_bow_compare.pdf"))
else:
    plot_confusion_single(y_test, knn_bow_labels, sorted_labels,
                          "KNN ‚Äî BoW (sau c√¢n b·∫±ng)",
                          save_path=os.path.join(PATHS.balanced, "knn_bow_balanced_cm.pdf"))

if 'knn_tfidf_labels_pre' in globals():
    compare_confusions(y_test, knn_tfidf_labels_pre, knn_tfidf_labels,
                       sorted_labels,
                       title_pre="KNN-TF-IDF (tr∆∞·ªõc c√¢n b·∫±ng)", title_post="KNN-TF-IDF (sau c√¢n b·∫±ng)",
                       save_path=os.path.join(PATHS.balanced, "knn_tfidf_compare.pdf"))
else:
    plot_confusion_single(y_test, knn_tfidf_labels, sorted_labels,
                          "KNN ‚Äî TF-IDF (sau c√¢n b·∫±ng)",
                          save_path=os.path.join(PATHS.balanced, "knn_tfidf_balanced_cm.pdf"))

if 'knn_emb_labels_pre' in globals():
    compare_confusions(y_test, knn_emb_labels_pre, knn_emb_labels,
                       sorted_labels,
                       title_pre="KNN-Emb (tr∆∞·ªõc c√¢n b·∫±ng)", title_post="KNN-Emb (sau c√¢n b·∫±ng)",
                       save_path=os.path.join(PATHS.balanced, "knn_emb_compare.pdf"))
else:
    plot_confusion_single(y_test, knn_emb_labels, sorted_labels,
                          "KNN ‚Äî Embeddings (sau c√¢n b·∫±ng)",
                          save_path=os.path.join(PATHS.balanced, "knn_emb_balanced_cm.pdf"))

# ====== V·∫º Decision Tree ======
if 'dt_bow_labels_pre' in globals():
    compare_confusions(y_test, dt_bow_labels_pre, dt_bow_labels,
                       sorted_labels,
                       title_pre="DT-BoW (tr∆∞·ªõc c√¢n b·∫±ng)", title_post="DT-BoW (sau c√¢n b·∫±ng)",
                       save_path=os.path.join(PATHS.balanced, "dt_bow_compare.pdf"))
else:
    plot_confusion_single(y_test, dt_bow_labels, sorted_labels,
                          "Decision Tree ‚Äî BoW (sau c√¢n b·∫±ng)",
                          save_path=os.path.join(PATHS.balanced, "dt_bow_balanced_cm.pdf"))

if 'dt_tfidf_labels_pre' in globals():
    compare_confusions(y_test, dt_tfidf_labels_pre, dt_tfidf_labels,
                       sorted_labels,
                       title_pre="DT-TF-IDF (tr∆∞·ªõc c√¢n b·∫±ng)", title_post="DT-TF-IDF (sau c√¢n b·∫±ng)",
                       save_path=os.path.join(PATHS.balanced, "dt_tfidf_compare.pdf"))
else:
    plot_confusion_single(y_test, dt_tfidf_labels, sorted_labels,
                          "Decision Tree ‚Äî TF-IDF (sau c√¢n b·∫±ng)",
                          save_path=os.path.join(PATHS.balanced, "dt_tfidf_balanced_cm.pdf"))

if 'dt_emb_labels_pre' in globals():
    compare_confusions(y_test, dt_emb_labels_pre, dt_emb_labels,
                       sorted_labels,
                       title_pre="DT-Emb (tr∆∞·ªõc c√¢n b·∫±ng)", title_post="DT-Emb (sau c√¢n b·∫±ng)",
                       save_path=os.path.join(PATHS.balanced, "dt_emb_compare.pdf"))
else:
    plot_confusion_single(y_test, dt_emb_labels, sorted_labels,
                          "Decision Tree ‚Äî Embeddings (sau c√¢n b·∫±ng)",
                          save_path=os.path.join(PATHS.balanced, "dt_emb_balanced_cm.pdf"))

# ====== V·∫º Naive Bayes ======
if 'nb_bow_labels_pre' in globals():
    compare_confusions(y_test, nb_bow_labels_pre, nb_bow_labels,
                       sorted_labels,
                       title_pre="NB-BoW (tr∆∞·ªõc c√¢n b·∫±ng)", title_post="NB-BoW (sau c√¢n b·∫±ng)",
                       save_path=os.path.join(PATHS.balanced, "nb_bow_compare.pdf"))
else:
    plot_confusion_single(y_test, nb_bow_labels, sorted_labels,
                          "Naive Bayes ‚Äî BoW (sau c√¢n b·∫±ng)",
                          save_path=os.path.join(PATHS.balanced, "nb_bow_balanced_cm.pdf"))

if 'nb_tfidf_labels_pre' in globals():
    compare_confusions(y_test, nb_tfidf_labels_pre, nb_tfidf_labels,
                       sorted_labels,
                       title_pre="NB-TF-IDF (tr∆∞·ªõc c√¢n b·∫±ng)", title_post="NB-TF-IDF (sau c√¢n b·∫±ng)",
                       save_path=os.path.join(PATHS.balanced, "nb_tfidf_compare.pdf"))
else:
    plot_confusion_single(y_test, nb_tfidf_labels, sorted_labels,
                          "Naive Bayes ‚Äî TF-IDF (sau c√¢n b·∫±ng)",
                          save_path=os.path.join(PATHS.balanced, "nb_tfidf_balanced_cm.pdf"))

if 'nb_emb_labels_pre' in globals():
    compare_confusions(y_test, nb_emb_labels_pre, nb_emb_labels,
                       sorted_labels,
                       title_pre="NB-Emb (tr∆∞·ªõc c√¢n b·∫±ng)", title_post="NB-Emb (sau c√¢n b·∫±ng)",
                       save_path=os.path.join(PATHS.balanced, "nb_emb_compare.pdf"))
else:
    plot_confusion_single(y_test, nb_emb_labels, sorted_labels,
                          "Naive Bayes ‚Äî Embeddings (sau c√¢n b·∫±ng)",
                          save_path=os.path.join(PATHS.balanced, "nb_emb_balanced_cm.pdf"))

# 6) L∆∞u CSV & K·∫øt lu·∫≠n nhanh
csv_path = "all_models_metrics.csv"
results_df_all.to_csv(csv_path, index=False)
lead = results_df_all.iloc[0]
print(f"üèÜ Top: {lead['model_feature']} | Acc={lead['accuracy']:.4f} | F1-macro={lead['f1_macro']:.4f}")
print(f"üìÅ Confusion Matrix ƒë√£ l∆∞u v√†o:\n - {PATHS.all_models} (t·∫•t c·∫£ m√¥ h√¨nh)\n - {PATHS.balanced} (so s√°nh c√¢n b·∫±ng)")
print(f"üíæ ƒê√£ l∆∞u: {csv_path}")



#**Streamlit**
# C√ÄI TH√äM G√ìI C·∫¶N THI·∫æT
%pip -q install joblib

import json, joblib, os
import numpy as np

# 1) L∆∞u b·∫£ng t·ªïng h·ª£p
results_df_all.to_csv("results_summary.csv", index=False)

# 2) L∆∞u mapping nh√£n
with open("id_to_label.json","w") as f:
    json.dump(id_to_label, f)            # keys s·∫Ω l√† str trong JSON
with open("sorted_labels.json","w") as f:
    json.dump(sorted_labels, f)

# 3) Ch·ªçn model t·ªët nh·∫•t
best = results_df_all.iloc[0]
best_name = best["model_feature"]
algo_name, feature_name = [x.strip() for x in best_name.split("‚Äî")]
feature_name = feature_name.lower()

# map t√™n ‚Üí model
def build_model(name):
    if name.startswith("LinearSVC"):   return LinearSVC(C=1.0, class_weight='balanced', random_state=42)
    if name.startswith("LogReg"):      return LogisticRegression(C=1.0, penalty='l2', solver='lbfgs',
                                                                 max_iter=2000, class_weight='balanced',
                                                                 random_state=42)
    if name.startswith("Ridge"):       return RidgeClassifier(alpha=1.0, class_weight='balanced', random_state=42)
    if name.startswith("KNN"):         return KNeighborsClassifier(n_neighbors=5)
    if name.startswith("Decision Tree"): return DecisionTreeClassifier(random_state=42, class_weight='balanced')
    if name.startswith("Naive Bayes"): return GaussianNB()
    raise ValueError(f"Kh√¥ng nh·∫≠n ra model: {name}")

# 4) L·∫•y ƒë√∫ng t·∫≠p train ƒë√£ c√¢n b·∫±ng theo feature + l∆∞u vectorizer n·∫øu c·∫ßn
if feature_name in ("bow",):
    Xtr, ytr = X_train_bow_bal,  y_train_bow_bal
    joblib.dump(bow_vectorizer, "bow_vectorizer.joblib")
elif feature_name in ("tf-idf","tfidf"):
    Xtr, ytr = X_train_tfidf_bal, y_train_tfidf_bal
    joblib.dump(tfidf_vectorizer, "tfidf_vectorizer.joblib")
else:
    feature_name = "embeddings"
    Xtr, ytr = X_train_emb_bal,  y_train_emb_bal

# 5) Train l·∫°i model best tr√™n full t·∫≠p train t∆∞∆°ng ·ª©ng r·ªìi l∆∞u
best_model = build_model(algo_name)
if isinstance(best_model, GaussianNB):
    Xtr = Xtr.toarray() if hasattr(Xtr, "toarray") else Xtr
best_model.fit(Xtr, ytr)
joblib.dump(best_model, "best_model.joblib")

# 6) L∆∞u metadata ƒë·ªÉ app bi·∫øt ph·∫£i d√πng g√¨ l√∫c suy lu·∫≠n
meta = {
    "feature": feature_name,
    "model_feature": best_name,
    "emb_model": "intfloat/multilingual-e5-base"   # t√™n SentenceTransformer d√πng cho embeddings
}
with open("best_meta.json","w") as f:
    json.dump(meta, f)

# 7) L∆∞u y_test + to√†n b·ªô d·ª± ƒëo√°n ƒë·ªÉ app v·∫Ω heatmap (DUY NH·∫§T 1 L·∫¶N)
np.save("y_test.npy", np.asarray(y_test, dtype=int))
VAR_MAP = {
    "KNN ‚Äî BoW": "knn_bow_labels",
    "KNN ‚Äî TF-IDF": "knn_tfidf_labels",
    "KNN ‚Äî Embeddings": "knn_emb_labels",
    "Decision Tree ‚Äî BoW": "dt_bow_labels",
    "Decision Tree ‚Äî TF-IDF": "dt_tfidf_labels",
    "Decision Tree ‚Äî Embeddings": "dt_emb_labels",
    "Naive Bayes ‚Äî BoW": "nb_bow_labels",
    "Naive Bayes ‚Äî TF-IDF": "nb_tfidf_labels",
    "Naive Bayes ‚Äî Embeddings": "nb_emb_labels",
    "LinearSVC ‚Äî BoW": "svc_bow_labels",
    "LinearSVC ‚Äî TF-IDF": "svc_tfidf_labels",
    "LinearSVC ‚Äî Embeddings": "svc_emb_labels",
    "LogReg ‚Äî BoW": "log_bow_labels",
    "LogReg ‚Äî TF-IDF": "log_tfidf_labels",
    "LogReg ‚Äî Embeddings": "log_emb_labels",
    "Ridge ‚Äî BoW": "ridge_bow_labels",
    "Ridge ‚Äî TF-IDF": "ridge_tfidf_labels",
    "Ridge ‚Äî Embeddings": "ridge_emb_labels",
}
preds = {disp: np.asarray(globals()[var], dtype=int).tolist()
         for disp, var in VAR_MAP.items() if var in globals()}
with open("preds.json","w") as f:
    json.dump(preds, f)

print("‚úÖ Saved: results_summary.csv, id_to_label.json, best_model.joblib, best_meta.json, preds.json, y_test.npy (+ vectorizer n·∫øu c·∫ßn)")
print("üèÜ Best:", best_name)

# ---------- app.py ----------
app_code = r"""
import os
import json, joblib, numpy as np, pandas as pd
import streamlit as st
import plotly.express as px
from sentence_transformers import SentenceTransformer

st.set_page_config(page_title='Model Leaderboard', layout='wide')

# ---------- Load d·ªØ li·ªáu ----------
df = pd.read_csv('results_summary.csv')
meta = json.load(open('best_meta.json'))
id_to_label = json.load(open('id_to_label.json'))
id_to_label = {int(k): v for k, v in id_to_label.items()}

sorted_labels = json.load(open('sorted_labels.json'))
preds_map = json.load(open('preds.json')) if os.path.exists('preds.json') else {}
y_test_arr = np.load('y_test.npy') if os.path.exists('y_test.npy') else np.array([])

if not preds_map or y_test_arr.size == 0:
    st.warning("Ch∆∞a c√≥ `preds.json` ho·∫∑c `y_test.npy`. H√£y ch·∫°y block xu·∫•t d·ª± ƒëo√°n trong notebook tr∆∞·ªõc khi m·ªü app.")
    st.stop()

st.title('üìä NLP Leaderboard & Inference Demo')

# ---------- Layout: tr√°i (F1/Acc/Leaderboard) ‚Äî ph·∫£i (Confusion Matrix) ----------
col_left, col_right = st.columns([1.3, 1])

with col_left:
    st.subheader('üìà Scores')
    tabs = st.tabs(['F1-macro (higher is better)', 'Accuracy', 'Leaderboard table'])

    import plotly.express as px
    with tabs[0]:
        fig1 = px.bar(df, x='model_feature', y='f1_macro', hover_data=['accuracy'])
        fig1.update_layout(xaxis_tickangle=-45, margin=dict(l=10, r=10, t=30, b=10), height=420)
        st.plotly_chart(fig1, use_container_width=True)

    with tabs[1]:
        fig2 = px.bar(df, x='model_feature', y='accuracy')
        fig2.update_layout(xaxis_tickangle=-45, margin=dict(l=10, r=10, t=30, b=10), height=420)
        st.plotly_chart(fig2, use_container_width=True)

    with tabs[2]:
        st.dataframe(
            df.style.format({'accuracy': '{:.4f}', 'f1_macro': '{:.4f}', 'f1_weighted': '{:.4f}'}),
            use_container_width=True, height=420
        )

with col_right:
    st.subheader('üìå Ch·ªçn m√¥ h√¨nh & xem Confusion Matrix')
    import matplotlib.pyplot as plt
    import seaborn as sns
    from sklearn.metrics import confusion_matrix

    model_opt = st.selectbox('M√¥ h√¨nh', list(preds_map.keys()), index=0)
    normalize = st.checkbox('Chu·∫©n h√≥a theo h√†ng (%)', value=True)

    y_pred_app = np.array(preds_map[model_opt], dtype=int)
    cm = confusion_matrix(y_test_arr, y_pred_app, labels=list(range(len(sorted_labels))))
    if normalize:
        row_sums = cm.sum(axis=1, keepdims=True).clip(min=1)
        cm_show = (cm / row_sums) * 100.0
        fmt = '.1f'
    else:
        cm_show = cm
        fmt = 'd'

    fig, ax = plt.subplots(figsize=(6.5, 5.2))
    sns.heatmap(cm_show, annot=True, fmt=fmt, cmap='Blues',
                xticklabels=sorted_labels, yticklabels=sorted_labels,
                cbar=False, linewidths=.5, linecolor='black', ax=ax)
    ax.set_xlabel('Predicted'); ax.set_ylabel('True'); ax.set_title(model_opt)
    st.pyplot(fig, use_container_width=True)

# ---------- Inference ----------
st.subheader('üîÆ ƒê·ªÅ xu·∫•t m√¥ h√¨nh t·ªët nh·∫•t & th·ª≠ d·ª± ƒëo√°n')
st.info(f"ƒê·ªÅ xu·∫•t: **{meta['model_feature']}**  |  Feature: `{meta['feature']}`")

text = st.text_area('Nh·∫≠p abstract/ƒëo·∫°n vƒÉn b·∫£n c·∫ßn ph√¢n lo·∫°i', height=160,
                    placeholder='Paste your text here...')
run = st.button('D·ª± ƒëo√°n')

if run and text.strip():
    model = joblib.load('best_model.joblib')
    feature = meta['feature']

    if feature == 'bow':
        vec = joblib.load('bow_vectorizer.joblib')
        X = vec.transform([text])
    elif feature in ('tf-idf', 'tfidf'):
        vec = joblib.load('tfidf_vectorizer.joblib')
        X = vec.transform([text])
    else:
        emb_model = meta.get('emb_model', 'intfloat/multilingual-e5-base')
        m = SentenceTransformer(emb_model)
        X = m.encode([f'query: {text}'], normalize_embeddings=True)
        X = np.array(X)

    if model.__class__.__name__ == 'GaussianNB':
        X = X.toarray() if hasattr(X, 'toarray') else X

    pred = int(model.predict(X)[0])
    st.success(f'K·∫øt qu·∫£: **{id_to_label[pred]}**')
"""
with open('app.py', 'w', encoding='utf-8') as f:
    f.write(app_code)

print("‚úÖ Created app.py")

# 1) ch·∫°y streamlit headless
!streamlit run app.py --server.port 8501 --server.headless true &> /content/streamlit.log &

# 2) t·∫£i cloudflared & m·ªü quick tunnel
!wget -q -O /content/cloudflared \
  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64
!chmod +x /content/cloudflared
!/content/cloudflared tunnel --url http://localhost:8501 --no-autoupdate > /content/cf.log 2>&1 &

# 3) l·∫•y public URL (ƒë·ª£i v√†i gi√¢y)
import time, re
for _ in range(20):
    time.sleep(1)
    log = open('/content/cf.log').read()
    m = re.search(r'https://[-0-9a-z]+\.trycloudflare\.com', log)
    if m:
        print("üîó Open this URL:", m.group(0))
        break
else:
    print("‚ö†Ô∏è Kh√¥ng th·∫•y URL, in log ƒë·ªÉ ki·ªÉm tra:\n", log[-2000:])
